{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language, Vision & AAC\n",
    "\n",
    "**Author:** Luke Steuber  \n",
    "**Date:** February 2026\n",
    "\n",
    "Exploring three accessibility datasets:\n",
    "1. **WLASL** - Word-Level American Sign Language video index (21,083 videos, 2,000 signs)\n",
    "2. **VizWiz** - Visual questions from blind users (4,319 questions with crowdsourced answers)\n",
    "3. **AAC Vocabulary** - Augmentative and Alternative Communication symbol libraries and core vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. WLASL: Word-Level American Sign Language\n",
    "\n",
    "Dataset of video recordings showing individual ASL signs with gloss labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WLASL dataset\n",
    "wlasl = pd.read_csv('../wlasl_index.csv')\n",
    "\n",
    "print(f\"Total records: {len(wlasl):,}\")\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(wlasl.info())\n",
    "print(f\"\\nFirst few records:\")\n",
    "wlasl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count videos per sign (gloss)\n",
    "videos_per_sign = wlasl.groupby('gloss').size().sort_values(ascending=False)\n",
    "\n",
    "print(f\"Unique signs (glosses): {len(videos_per_sign):,}\")\n",
    "print(f\"Average videos per sign: {videos_per_sign.mean():.1f}\")\n",
    "print(f\"Median videos per sign: {videos_per_sign.median():.0f}\")\n",
    "print(f\"\\nTop 10 most-recorded signs:\")\n",
    "print(videos_per_sign.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Distribution of videos per sign\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(videos_per_sign, bins=30, color='#2E86AB', edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('Number of Videos per Sign')\n",
    "ax1.set_ylabel('Frequency (Number of Signs)')\n",
    "ax1.set_title('Distribution of Videos per Sign (WLASL)', fontweight='bold', fontsize=13)\n",
    "ax1.axvline(videos_per_sign.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {videos_per_sign.mean():.1f}')\n",
    "ax1.axvline(videos_per_sign.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {videos_per_sign.median():.0f}')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Top 15 signs\n",
    "top_15 = videos_per_sign.head(15)\n",
    "ax2.barh(range(len(top_15)), top_15.values, color='#A23B72')\n",
    "ax2.set_yticks(range(len(top_15)))\n",
    "ax2.set_yticklabels(top_15.index)\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_xlabel('Number of Videos')\n",
    "ax2.set_title('Top 15 Most-Recorded Signs', fontweight='bold', fontsize=13)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VizWiz: Visual Questions from Blind Users\n",
    "\n",
    "Crowdsourced visual question answering dataset where blind users ask questions about images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VizWiz dataset\n",
    "vizwiz = pd.read_csv('../vizwiz_val_annotations.csv')\n",
    "\n",
    "print(f\"Total questions: {len(vizwiz):,}\")\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(vizwiz.info())\n",
    "print(f\"\\nFirst few records:\")\n",
    "vizwiz.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze answerability\n",
    "if 'answerable' in vizwiz.columns:\n",
    "    answerable_counts = vizwiz['answerable'].value_counts()\n",
    "    print(\"Answerability distribution:\")\n",
    "    print(answerable_counts)\n",
    "    print(f\"\\nAnswerable rate: {answerable_counts.get(True, 0) / len(vizwiz) * 100:.1f}%\")\n",
    "\n",
    "# Sample questions\n",
    "if 'question' in vizwiz.columns:\n",
    "    print(\"\\nSample questions:\")\n",
    "    for i, q in enumerate(vizwiz['question'].dropna().sample(5).values, 1):\n",
    "        print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Answerable vs Unanswerable\n",
    "if 'answerable' in vizwiz.columns:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Pie chart\n",
    "    labels = ['Answerable', 'Unanswerable']\n",
    "    sizes = [answerable_counts.get(True, 0), answerable_counts.get(False, 0)]\n",
    "    colors = ['#06A77D', '#D84E4E']\n",
    "    explode = (0.05, 0)\n",
    "    \n",
    "    ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "            startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "    ax1.set_title('VizWiz Questions: Answerability', fontweight='bold', fontsize=13)\n",
    "    \n",
    "    # Bar chart with counts\n",
    "    ax2.bar(labels, sizes, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    ax2.set_ylabel('Number of Questions')\n",
    "    ax2.set_title('Question Counts by Answerability', fontweight='bold', fontsize=13)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, (label, count) in enumerate(zip(labels, sizes)):\n",
    "        ax2.text(i, count + 50, f'{count:,}', ha='center', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'answerable' column not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AAC Vocabulary: Symbol Libraries and Core Vocabularies\n",
    "\n",
    "Augmentative and Alternative Communication resources including symbol libraries (ARASAAC, GlobalSymbols) and core vocabulary lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AAC vocabulary data\n",
    "with open('../aac_vocabulary_data.json', 'r') as f:\n",
    "    aac = json.load(f)\n",
    "\n",
    "print(\"AAC Vocabulary Data Structure:\")\n",
    "print(f\"Keys: {list(aac.keys())}\")\n",
    "\n",
    "if 'core_vocabulary_lists' in aac:\n",
    "    print(f\"\\nCore Vocabulary Lists: {list(aac['core_vocabulary_lists'].keys())}\")\n",
    "\n",
    "if 'symbol_libraries' in aac:\n",
    "    print(f\"\\nSymbol Libraries: {list(aac['symbol_libraries'].keys())}\")\n",
    "\n",
    "if 'global_symbols_libraries' in aac:\n",
    "    print(f\"\\nGlobal Symbols Libraries: {len(aac['global_symbols_libraries'])} libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Global Symbols libraries\n",
    "if 'global_symbols_libraries' in aac:\n",
    "    libraries_df = pd.DataFrame(aac['global_symbols_libraries'])\n",
    "    \n",
    "    print(f\"Total symbol libraries: {len(libraries_df)}\")\n",
    "    print(f\"\\nTop 10 largest symbol libraries:\")\n",
    "    top_libraries = libraries_df.nlargest(10, 'symbol_count')\n",
    "    print(top_libraries[['name', 'publisher', 'symbol_count']])\n",
    "    \n",
    "    print(f\"\\nTotal symbols across all libraries: {libraries_df['symbol_count'].sum():,}\")\n",
    "    print(f\"Average library size: {libraries_df['symbol_count'].mean():.0f} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Symbol libraries by size\n",
    "if 'global_symbols_libraries' in aac:\n",
    "    libraries_df = pd.DataFrame(aac['global_symbols_libraries'])\n",
    "    top_15_libs = libraries_df.nlargest(15, 'symbol_count').sort_values('symbol_count')\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = plt.cm.viridis(range(len(top_15_libs)))\n",
    "    bars = plt.barh(range(len(top_15_libs)), top_15_libs['symbol_count'], color=colors, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    plt.yticks(range(len(top_15_libs)), top_15_libs['name'])\n",
    "    plt.xlabel('Number of Symbols', fontweight='bold')\n",
    "    plt.title('Top 15 AAC Symbol Libraries by Size', fontweight='bold', fontsize=14)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, (idx, row) in enumerate(top_15_libs.iterrows()):\n",
    "        plt.text(row['symbol_count'] + 200, i, f\"{row['symbol_count']:,}\", \n",
    "                va='center', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore core vocabularies\n",
    "if 'core_vocabulary_lists' in aac:\n",
    "    print(\"Core Vocabulary Lists:\")\n",
    "    for vocab_name, vocab_data in aac['core_vocabulary_lists'].items():\n",
    "        if isinstance(vocab_data, dict):\n",
    "            words = vocab_data.get('words', [])\n",
    "            print(f\"\\n{vocab_name}:\")\n",
    "            print(f\"  Total words: {len(words)}\")\n",
    "            if words:\n",
    "                print(f\"  Sample words: {', '.join(words[:15])}\")\n",
    "                \n",
    "                # Word length distribution\n",
    "                word_lengths = [len(w) for w in words]\n",
    "                print(f\"  Average word length: {sum(word_lengths) / len(word_lengths):.1f} characters\")\n",
    "        elif isinstance(vocab_data, list):\n",
    "            print(f\"\\n{vocab_name}:\")\n",
    "            print(f\"  Total words: {len(vocab_data)}\")\n",
    "            print(f\"  Sample words: {', '.join(vocab_data[:15])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Core vocabulary comparison\n",
    "if 'core_vocabulary_lists' in aac:\n",
    "    vocab_sizes = {}\n",
    "    \n",
    "    for vocab_name, vocab_data in aac['core_vocabulary_lists'].items():\n",
    "        if isinstance(vocab_data, dict):\n",
    "            vocab_sizes[vocab_name] = len(vocab_data.get('words', []))\n",
    "        elif isinstance(vocab_data, list):\n",
    "            vocab_sizes[vocab_name] = len(vocab_data)\n",
    "    \n",
    "    if vocab_sizes:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        names = list(vocab_sizes.keys())\n",
    "        sizes = list(vocab_sizes.values())\n",
    "        colors = ['#E63946', '#F1FAEE', '#A8DADC', '#457B9D', '#1D3557'][:len(names)]\n",
    "        \n",
    "        bars = plt.bar(names, sizes, color=colors, edgecolor='black', linewidth=2)\n",
    "        plt.ylabel('Number of Words', fontweight='bold')\n",
    "        plt.title('Core Vocabulary Lists Comparison', fontweight='bold', fontsize=14)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add count labels on bars\n",
    "        for bar, size in zip(bars, sizes):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{size}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "        \n",
    "        plt.xticks(rotation=15, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "### WLASL (Word-Level American Sign Language)\n",
    "- **21,083 videos** covering **2,000 unique signs**\n",
    "- Average of ~10 videos per sign (enables machine learning for sign recognition)\n",
    "- Distribution shows some signs have many more videos than others (training data imbalance)\n",
    "\n",
    "### VizWiz (Visual Questions from Blind Users)\n",
    "- **4,319 questions** from blind users about images\n",
    "- Mix of answerable and unanswerable questions (image quality, clarity issues)\n",
    "- Real-world dataset showing actual information needs of blind users\n",
    "- Crowdsourced answers provide ground truth for training vision models\n",
    "\n",
    "### AAC Vocabulary (Augmentative Communication)\n",
    "- **34 symbol libraries** with varying sizes (from hundreds to tens of thousands of symbols)\n",
    "- ARASAAC: 13,709 pictograms (one of the largest open symbol sets)\n",
    "- Core vocabularies: PRC-Saltillo (100 words), Project Core (36 words)\n",
    "- Symbol libraries serve different languages, cultures, and communication needs\n",
    "- Core vocabularies focus on high-frequency words for efficient communication\n",
    "\n",
    "### Cross-Dataset Insights\n",
    "All three datasets address different aspects of accessibility:\n",
    "- **WLASL**: Visual-gestural communication (deaf/hard of hearing)\n",
    "- **VizWiz**: Visual accessibility for blind users\n",
    "- **AAC**: Communication support for non-verbal individuals\n",
    "\n",
    "Together they represent the diversity of accessibility needs and technological approaches to addressing them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
